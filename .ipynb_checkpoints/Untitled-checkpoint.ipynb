{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Newton Notations in the Convex Optimization of S.Boyd\n",
    "# Trust region notation from Numerical Optimization of J.Nocedal\n",
    "import numpy as np\n",
    "import math\n",
    "def log(x):\n",
    "    try:\n",
    "        return math.log(x)\n",
    "    except ValueError:\n",
    "        return math.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search(f,\n",
    "                x: \"starting point in the feasible domain of f\",\n",
    "                Delta_x: \"descent direction\",\n",
    "                gradient_f_x: \"gradient of f at x\",\n",
    "                a: \"affinity of approximation\" = 0.25,\n",
    "                b: \"decreasing rate\" = 0.5) -> \"step size\":\n",
    "    \"\"\"Backtracking line search in the Convex Optimization of S.Boyd page 464.\"\"\"\n",
    "    t = 1\n",
    "    while f(x + t*Delta_x) > f(x) + a*t*gradient_f_x @ Delta_x:\n",
    "        t = b*t\n",
    "    return t\n",
    "\n",
    "def newton_method(\n",
    "        f: \"convex function to be minimized\",\n",
    "        x: \"starting point in the feasible domain of f\",\n",
    "        e: \"tolerance, >0\",\n",
    "        gradient_f,\n",
    "        hessian_f,\n",
    "        a: \"line search parameter, affinity of approximation\" = 0.25,\n",
    "        b: \"line search parameter, decreasing rate\" = 0.5) -> \"x*\":\n",
    "    \"\"\"Newton's method in the page 487\"\"\"\n",
    "    while True:\n",
    "        Grad_f_x = gradient_f(x)\n",
    "        hfx = hessian_f(x)\n",
    "        Hess_f_x_inv = np.linalg.inv(hessian_f(x))\n",
    "        \n",
    "        decrement = Grad_f_x @ Hess_f_x_inv @ Grad_f_x\n",
    "        if decrement/2 <= e:\n",
    "            return x\n",
    "        newton_step = -Hess_f_x_inv * Grad_f_x\n",
    "\n",
    "        t = line_search(f, x, newton_step, Grad_f_x, a, b)\n",
    "        x = x + t*newton_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inegality_constraints(\n",
    "        f0: \"convex function to be minimized\",\n",
    "        constraints: \"list of convex inegality constraints\",\n",
    "        x:  \"strictly feasible starting point\",\n",
    "        e:  \"tolerance, >0\",\n",
    "        grad_f_s: \"list of gradients from f0 to fm\",\n",
    "        hess_f_s: \"list of hessians from f0 to fm\",\n",
    "        t:  \"t0 > 0\" = 1,\n",
    "        nu: \"> 1\" = 5) -> \"x*\":\n",
    "\n",
    "    n = x.size\n",
    "    m = len(constraints)\n",
    "    grad_f0 = grad_f_s[0]\n",
    "    hess_f0 = hess_f_s[0]\n",
    "    grad_constraints = grad_f_s[1:]\n",
    "    hess_constraints = hess_f_s[1:]\n",
    "\n",
    "    # _ = -constraints[0](x)\n",
    "\n",
    "    def phi(x): \n",
    "        print(x)\n",
    "        # for f_i in constraints:\n",
    "        #     print(f_i(x))\n",
    "        \n",
    "        return -sum(log(-f_i(x)) for f_i in constraints)\n",
    "    def grad_phi(x):\n",
    "        return sum(-1/(constraints[i](x)) * grad_constraints[i](x) for i in range(m))\n",
    "    def hess_phi(x):\n",
    "        l = []\n",
    "        for i in range(m):\n",
    "            fi_x = constraints[i](x)\n",
    "            hess_fi_x = hess_constraints[i](x)\n",
    "            grad_fi_x = grad_constraints[i](x)\n",
    "\n",
    "            part1 = hess_fi_x/fi_x\n",
    "\n",
    "            _l = [grad_fi_x[j]*grad_fi_x[k] for j in range(n) for k in range(n)]\n",
    "            part2 = np.reshape(_l, (n,n)) / fi_x**2\n",
    "\n",
    "            l.append(part1 + part2)\n",
    "        return sum(l)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        x_star_t = newton_method(lambda x: t * f0(x) + phi(x),\n",
    "                                 x, e,\n",
    "                                 lambda x: t* grad_f0(x) + grad_phi(x),\n",
    "                                 lambda x: t* hess_f0(x) + hess_phi(x))\n",
    "        x = x_star_t\n",
    "        if m/t < e:\n",
    "            return x\n",
    "        t = nu * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1\n",
    "g = -2 * np.ones(3)\n",
    "B = 2 * np.eye(3)\n",
    "\n",
    "Delta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.size(g)\n",
    "p0 = np.zeros(n)\n",
    "\n",
    "def m(p): return f + g @ p + 1/2 * p @ B @ p\n",
    "\n",
    "def grad_m(p): return g + B @ p\n",
    "\n",
    "def hess_m(p): return B\n",
    "\n",
    "def c(p): \n",
    "    \"\"\"Constraint function of trust region.\"\"\"\n",
    "    return p @ p - Delta**2\n",
    "\n",
    "def grad_c(p): return 2 * p\n",
    "\n",
    "def hess_c(p): return 2 * np.eye(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = m\n",
    "constraints = [c]\n",
    "x = p0\n",
    "e = 1e-6\n",
    "grad_f_s = [grad_m, grad_c]\n",
    "hess_f_s = [hess_m, hess_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    n = x.size\n",
    "    m = len(constraints)\n",
    "    grad_f0 = grad_f_s[0]\n",
    "    hess_f0 = hess_f_s[0]\n",
    "    grad_constraints = grad_f_s[1:]\n",
    "    hess_constraints = hess_f_s[1:]\n",
    "\n",
    "    # _ = -constraints[0](x)\n",
    "\n",
    "    def phi(x): \n",
    "        print(x)\n",
    "        # for f_i in constraints:\n",
    "        #     print(f_i(x))\n",
    "        \n",
    "        return -sum(log(-f_i(x)) for f_i in constraints)\n",
    "    def grad_phi(x):\n",
    "        return sum(-1/(constraints[i](x)) * grad_constraints[i](x) for i in range(m))\n",
    "    def hess_phi(x):\n",
    "        l = []\n",
    "        for i in range(m):\n",
    "            fi_x = constraints[i](x)\n",
    "            hess_fi_x = hess_constraints[i](x)\n",
    "            grad_fi_x = grad_constraints[i](x)\n",
    "\n",
    "            part1 = hess_fi_x/fi_x\n",
    "\n",
    "            _l = [grad_fi_x[j]*grad_fi_x[k] for j in range(n) for k in range(n)]\n",
    "            part2 = np.reshape(_l, (n,n)) / fi_x**2\n",
    "\n",
    "            l.append(part1 + part2)\n",
    "        return sum(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-60adf649d127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                          \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mgrad_f0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgrad_phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                          lambda x: t* hess_f0(x) + hess_phi(x))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-57e384e9bdc7>\u001b[0m in \u001b[0;36mnewton_method\u001b[0;34m(f, x, e, gradient_f, hessian_f, a, b)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m\"\"\"Newton's method in the page 487\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mGrad_f_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mhfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhessian_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mHess_f_x_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhessian_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-60adf649d127>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m x_star_t = newton_method(lambda x: t * f0(x) + phi(x),\n\u001b[1;32m      2\u001b[0m                          \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                          \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mgrad_f0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgrad_phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                          lambda x: t* hess_f0(x) + hess_phi(x))\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "        x_star_t = newton_method(lambda x: t * f0(x) + phi(x),\n",
    "                                 x, e,\n",
    "                                 lambda x: t* grad_f0(x) + grad_phi(x),\n",
    "                                 lambda x: t* hess_f0(x) + hess_phi(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inegality_constraints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bf32f14089a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minegality_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrad_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhess_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inegality_constraints' is not defined"
     ]
    }
   ],
   "source": [
    "inegality_constraints(m, [c], p0, 1e-6, [grad_m, grad_c], [hess_m, hess_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_TR_subproblem(f: \"f(x_k)\",\n",
    "                        g: \"Grad f(x_k)\",\n",
    "                        B: \"B_k symmetic and uniformly bounded, Aprox Hess of f(x_k)\",\n",
    "                        Delta: \"Delta_k > 0, Trust Region radius\") -> \"p_k\":\n",
    "    \"\"\"Solve min_p m(p) = f_k + g_k^T p + 1/2 p^T B_k p\n",
    "                s.t. ||p|| <= Delta_k.\n",
    "        the type of g needs to support @ operation\"\"\"\n",
    "\n",
    "    def difficult_case():\n",
    "        n = np.size(g)\n",
    "        p0 = np.zeros(n)\n",
    "            \n",
    "        def m(p): return f + g @ p + 1/2 * p @ B @ p\n",
    "\n",
    "        def grad_m(p): return g + B @ p\n",
    "\n",
    "        def hess_m(p): return B\n",
    "\n",
    "        def c(p): \n",
    "            \"\"\"Constraint function of trust region.\"\"\"\n",
    "            return p @ p - Delta**2\n",
    "\n",
    "        def grad_c(p): return 2 * p\n",
    "\n",
    "        def hess_c(p): return 2 * np.eye(n)\n",
    "\n",
    "        return inegality_constraints(m, [c], p0, 1e-6, [grad_m, grad_c], [hess_m, hess_c])\n",
    "\n",
    "    \n",
    "        \n",
    "    try:\n",
    "        B_inv = np.linalg.inv(B) #if B is positive definite and symetric\n",
    "        sol = B_inv @ g\n",
    "        if np.linalg.norm(sol) <= Delta:\n",
    "            return sol\n",
    "        else:\n",
    "            return difficult_case()\n",
    "\n",
    "    except np.linalg.LinAlgError:\n",
    "\n",
    "        return difficult_case()\n",
    "\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
